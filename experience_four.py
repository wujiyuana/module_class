"""
pdfæ™ºèƒ½åˆ†æåŠ©æ‰‹
"""
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.chat_models import ChatTongyi
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import streamlit as st


def get_chat_response(memory,uploaded_file,question):
    file_contents = uploaded_file.read()
    temp_file_path = "temp.pdf"
    with open(temp_file_path,"wb") as temp_file:
        temp_file.write(file_contents)
    loader = PyPDFLoader(temp_file_path)
    documents = loader.load()

    # åˆ†å‰²æ–‡æ¡£
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,
        chunk_overlap=20,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", "ã€", ""]
    )
    texts = text_splitter.split_documents(documents)

    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embeddings_model = DashScopeEmbeddings(model="text-embedding-v1", )

    # åˆ›å»ºå‘é‡æ•°æ®åº“
    db = FAISS.from_documents(texts, embeddings_model)

    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = db.as_retriever()

    # åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
    tongyi_model = ChatTongyi(model="qwen-plus")

    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=tongyi_model,
        retriever=retriever,
        memory=memory
    )
    response = qa_chain.invoke({"chat_history":memory,"question":question})
    return response['answer']
st.set_page_config(
    page_title="å°é¸¢çš„æ•°æ®åˆ†æåŠ©æ‰‹",  # æ ‡ç­¾é¡µçš„åç§°
    page_icon="ğŸš€"         # æ ‡ç­¾é¡µçš„å›¾æ ‡ï¼Œå¯ä»¥æ˜¯ emoji æˆ– URLğŸ²"ğŸŒŸ"ğŸš€
)
#æ·»åŠ ä¸€ä¸ªæ ‡é¢˜
st.title('ğŸŒŸpdfæ™ºèƒ½å°åŠ©æ‰‹')
if "memory" not in st.session_state:
    st.session_state["memory"]=ConversationBufferMemory(
        return_messages=True, memory_key='chat_history', output_key='answer'
    )
pdf = st.file_uploader("è¯·ä¸Šä¼ .pdfæ–‡ä»¶",type="pdf")
query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
if st.button("å‘é€"):
    response1 = get_chat_response(st.session_state["memory"],pdf,query)
    st.write(response1)

# ç”¨æˆ·è¾“å…¥
# query = "æ‚è¯—åäºŒé¦–çš„ä½œè€…æ˜¯è°ï¼Ÿ"

# # ç”Ÿæˆå“åº”
# response = qa_chain.invoke({"chat_history": memory, "question": query})
# print(f"Response: {response['answer']}")
#
# # ç”¨æˆ·ç»§ç»­æé—®
# follow_up_query = "å…¶ä¸­å’Œå²æœˆç›¸å…³çš„è¯—å¥æœ‰å“ªäº›ï¼Ÿ"
# follow_up_response = qa_chain.invoke({"chat_history": memory, "question": follow_up_query})
# print(f"Follow-up Response: {follow_up_response['answer']}")
